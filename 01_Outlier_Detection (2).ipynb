{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99827ab-9632-4ee6-b6dd-abc2cde9948f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>estimated_housing_payment</th>\n",
       "      <th>dti_adjusted</th>\n",
       "      <th>ltv_proxy</th>\n",
       "      <th>composite_risk_score</th>\n",
       "      <th>credit_history_length_months</th>\n",
       "      <th>ZHVI_missing</th>\n",
       "      <th>ZHVI_lag_1_missing</th>\n",
       "      <th>ZHVI_lag_3_missing</th>\n",
       "      <th>ZHVI_lag_6_missing</th>\n",
       "      <th>ZHVI_lag_12_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>22.35</td>\n",
       "      <td>1151.16</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2292.481910</td>\n",
       "      <td>57.969783</td>\n",
       "      <td>0.052345</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>16.14</td>\n",
       "      <td>975.71</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>421.048347</td>\n",
       "      <td>61.757956</td>\n",
       "      <td>0.380004</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>622.68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1577.879733</td>\n",
       "      <td>37.854557</td>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>11.31</td>\n",
       "      <td>147.99</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>38500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1155.625700</td>\n",
       "      <td>40.659502</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.166133</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8425</td>\n",
       "      <td>0</td>\n",
       "      <td>27.27</td>\n",
       "      <td>345.18</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2262.750343</td>\n",
       "      <td>18.404001</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  installment  grade  sub_grade  emp_length  \\\n",
       "0      30000     0     22.35      1151.16      3         19           5   \n",
       "1      40000     1     16.14       975.71      2         13          10   \n",
       "2      20000     0      7.56       622.68      0          2           1   \n",
       "3       4500     0     11.31       147.99      1          7           1   \n",
       "4       8425     0     27.27       345.18      4         24           3   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  ...  \\\n",
       "0               1    100000.0                    1  ...   \n",
       "1               1     45000.0                    2  ...   \n",
       "2               1    100000.0                    0  ...   \n",
       "3               5     38500.0                    0  ...   \n",
       "4               1    450000.0                    2  ...   \n",
       "\n",
       "  estimated_housing_payment  dti_adjusted  ltv_proxy  composite_risk_score  \\\n",
       "0               2292.481910     57.969783   0.052345              0.436200   \n",
       "1                421.048347     61.757956   0.380004              0.399600   \n",
       "2               1577.879733     37.854557   0.050701              0.151233   \n",
       "3               1155.625700     40.659502   0.015576              0.166133   \n",
       "4               2262.750343     18.404001   0.014893              0.457900   \n",
       "\n",
       "  credit_history_length_months  ZHVI_missing  ZHVI_lag_1_missing  \\\n",
       "0                           82             0                   0   \n",
       "1                          113             0                   0   \n",
       "2                          237             0                   0   \n",
       "3                          179             0                   0   \n",
       "4                          253             0                   0   \n",
       "\n",
       "   ZHVI_lag_3_missing  ZHVI_lag_6_missing  ZHVI_lag_12_missing  \n",
       "0                   0                   0                    0  \n",
       "1                   0                   0                    0  \n",
       "2                   0                   0                    0  \n",
       "3                   0                   0                    0  \n",
       "4                   0                   0                    0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('final_dataset_enhanced.parquet', engine='fastparquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24779a2f-c3c5-4c32-be00-20af58854ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306387, 151)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b628e6-fbb0-4ba0-8258-16de6e0c27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4149bbbd-7c4c-421f-aa37-42361e90f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded and complete (0 NaN).\n"
     ]
    }
   ],
   "source": [
    "# Quick check to ensure no missing values remain\n",
    "assert df.isnull().sum().sum() == 0, \"Warning: Missing values found!\"\n",
    "print(\" Dataset loaded and complete (0 NaN).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b14799d-7abe-4975-9eba-ef637cba6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time period covered: 2007-06-01 00:00:00 to 2018-12-01 00:00:00\n",
      " Non-numeric columns dropped automatically: ['earliest_cr_line']\n",
      "\n",
      "Train set : (1045109, 148)\n",
      "Test set  : (261278, 148)\n"
     ]
    }
   ],
   "source": [
    "# 2. Temporal Preparation & Type Cleaning\n",
    "if 'issue_d' in df.columns:\n",
    "    # Convert to datetime if not already done\n",
    "    df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "    \n",
    "    # Chronological sort (Important for financial data)\n",
    "    df = df.sort_values('issue_d')\n",
    "    \n",
    "    print(f\"Time period covered: {df['issue_d'].min()} to {df['issue_d'].max()}\")\n",
    "    \n",
    "    # Save the date aside for reference\n",
    "    df_dates = df['issue_d']\n",
    "    df_model = df.drop(columns=['issue_d'])\n",
    "else:\n",
    "    print(\" Column 'issue_d' not found.\")\n",
    "    df_model = df.copy()\n",
    "\n",
    "#  Keep only numeric columns \n",
    "# This automatically eliminates any remaining date or text columns\n",
    "X_numeric = df_model.select_dtypes(include=['number'])\n",
    "\n",
    "# Check which columns were dropped (for information)\n",
    "dropped_cols = set(df_model.columns) - set(X_numeric.columns)\n",
    "if len(dropped_cols) > 0:\n",
    "    print(f\" Non-numeric columns dropped automatically: {list(dropped_cols)}\")\n",
    "\n",
    "# 3. Split 80% Train / 20% Test (Chronological)\n",
    "split_idx = int(len(X_numeric) * 0.80)\n",
    "\n",
    "# Separate Target and Features\n",
    "X = X_numeric.drop(columns=['loan_status_binary'])\n",
    "y = X_numeric['loan_status_binary']\n",
    "\n",
    "X_train = X.iloc[:split_idx].copy()\n",
    "X_test = X.iloc[split_idx:].copy()\n",
    "y_train = y.iloc[:split_idx].copy()\n",
    "y_test = y.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"\\nTrain set : {X_train.shape}\")\n",
    "print(f\"Test set  : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661eab8f-be99-46f3-bb1a-1e5bec8dfa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Isolation Forest on the Train Set\n",
      "Creating anomaly features\n",
      "Features 'anomaly_score' and 'is_outlier' added successfully.\n",
      "Average anomaly score (Train): 0.1065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Outliers detection\n",
    "print(\"Training Isolation Forest on the Train Set\")\n",
    "\n",
    "iso = IsolationForest(contamination=0.01, random_state=42, n_jobs=-1)\n",
    "iso.fit(X_train)\n",
    "\n",
    "print(\"Creating anomaly features\")\n",
    "\n",
    "# Calculating scores (without modifying X_train just yet)\n",
    "train_scores = iso.decision_function(X_train)\n",
    "test_scores = iso.decision_function(X_test)\n",
    "\n",
    "# Calculating flags \n",
    "train_flags = iso.predict(X_train)\n",
    "test_flags = iso.predict(X_test)\n",
    "\n",
    "# Now we can add columns without problem\n",
    "X_train['anomaly_score'] = train_scores\n",
    "X_test['anomaly_score'] = test_scores\n",
    "\n",
    "X_train['is_outlier'] = train_flags\n",
    "X_test['is_outlier'] = test_flags\n",
    "\n",
    "print(\"Features 'anomaly_score' and 'is_outlier' added successfully.\")\n",
    "print(f\"Average anomaly score (Train): {X_train['anomaly_score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577b7474-3659-4866-b0a7-fbb930a70b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Safety Clipping (99.9%)\n",
      "  - annual_inc: clipped at 550000.00\n",
      "  - revol_bal: clipped at 265443.78\n",
      "  - tot_cur_bal: clipped at 1198550.51\n",
      "  - total_acc: clipped at 79.00\n",
      "  - loan_amnt: clipped at 40000.00\n",
      "  - installment: clipped at 1321.87\n",
      " Extreme anomalies handled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagro\\AppData\\Local\\Temp\\ipykernel_115556\\169846724.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '265443.7840000002' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[X_train[col] > upper_limit, col] = upper_limit\n",
      "C:\\Users\\sagro\\AppData\\Local\\Temp\\ipykernel_115556\\169846724.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '265443.7840000002' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[X_test[col] > upper_limit, col] = upper_limit\n"
     ]
    }
   ],
   "source": [
    "# 4. Safety Clipping (Handling Data Errors only)\n",
    "# Decision Trees handle skewness well, but we remove impossible/error values\n",
    "# by clipping at the 99.9th percentile.\n",
    "\n",
    "cols_financial = ['annual_inc', 'revol_bal', 'tot_cur_bal', 'total_acc', 'loan_amnt', 'installment']\n",
    "\n",
    "print(\"Applying Safety Clipping (99.9%)\")\n",
    "\n",
    "for col in cols_financial:\n",
    "    if col in X_train.columns:\n",
    "        # Calculate limit on Train\n",
    "        upper_limit = X_train[col].quantile(0.999)\n",
    "        \n",
    "        # Apply to Train and Test\n",
    "        X_train.loc[X_train[col] > upper_limit, col] = upper_limit\n",
    "        X_test.loc[X_test[col] > upper_limit, col] = upper_limit\n",
    "        \n",
    "        print(f\"  - {col}: clipped at {upper_limit:.2f}\")\n",
    "\n",
    "print(\" Extreme anomalies handled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92ee1fd-a49b-4829-a991-defe5379d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropping 45 redundant features\n",
      "Features remaining: 105\n"
     ]
    }
   ],
   "source": [
    "# 5. Drop Highly Correlated Features (> 0.95)\n",
    "# Removing redundancy speeds up training and makes the model lighter\n",
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "print(f\"\\nDropping {len(to_drop)} redundant features\")\n",
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "\n",
    "print(f\"Features remaining: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7a76a1-4af8-46c1-b9c6-26d95556e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and correcting infinite values\n",
      "   22 infinite values detected. Replacing...\n",
      "    - Column dti_adjusted corrected (replaced by 874209.42)\n",
      "   280 infinite values detected. Replacing...\n",
      "    - Column dti_adjusted corrected (replaced by 5476278.84)\n",
      "Data ready for Scaling.\n"
     ]
    }
   ],
   "source": [
    "# Infinite Value Correction \n",
    "# Division by zero during Feature Engineering may have created 'inf' values.\n",
    "\n",
    "print(\"Checking and correcting infinite values\")\n",
    "\n",
    "def replace_infinite_values(df):\n",
    "    # Count infinite values\n",
    "    inf_count = np.isinf(df.select_dtypes(include=np.number)).sum().sum()\n",
    "    \n",
    "    if inf_count > 0:\n",
    "        print(f\"   {inf_count} infinite values detected. Replacing...\")\n",
    "        \n",
    "        # Replace +/- inf with NaN\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Replace NaN with the column's max value\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().any():\n",
    "                # Fill with the maximum observed value\n",
    "                fill_val = df[col].max()\n",
    "                df[col] = df[col].fillna(fill_val)\n",
    "                print(f\"    - Column {col} corrected (replaced by {fill_val:.2f})\")\n",
    "    else:\n",
    "        print(\"No infinite values found.\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Apply to Train and Test sets\n",
    "X_train = replace_infinite_values(X_train)\n",
    "X_test = replace_infinite_values(X_test)\n",
    "\n",
    "print(\"Data ready for Scaling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52dbe672-3464-4ab3-9c5e-ab20d3a47bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Scaled.\n"
     ]
    }
   ],
   "source": [
    "# 6. Scaling (RobustScaler)\n",
    "# Critical for SMOTE to calculate distances correctly\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit on Train, Transform on Train and Test\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\" Data Scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283818ed-5a63-418e-8cb0-8fbe8280eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution before SMOTE:\n",
      "loan_status_binary\n",
      "0    0.803019\n",
      "1    0.196981\n",
      "Name: proportion, dtype: float64\n",
      "Running SMOTE\n",
      "Target distribution after SMOTE:\n",
      "loan_status_binary\n",
      "0    0.666667\n",
      "1    0.333333\n",
      "Name: proportion, dtype: float64\n",
      "Final Train shape: (1258863, 105)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 7. SMOTE (On train only)\n",
    "print(f\"\\nTarget distribution before SMOTE:\\n{y_train.value_counts(normalize=True)}\")\n",
    "\n",
    "# Strategy 0.5 is good for Trees \n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "\n",
    "print(\"Running SMOTE\")\n",
    "X_train_final, y_train_final = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Target distribution after SMOTE:\\n{y_train_final.value_counts(normalize=True)}\")\n",
    "print(f\"Final Train shape: {X_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c4b5846-7e31-4cb7-b56e-5892aa0c1804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data ready for training\n",
      "Files created \n"
     ]
    }
   ],
   "source": [
    "# 8. Save for Modeling\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# Save features (X) in Parquet for speed\n",
    "X_train_final.to_parquet('C:\\\\ESILV A4\\\\ESILV A4 DIA\\\\Machine Learning\\\\Projet ML\\\\X_train_tree_ready.parquet', engine='fastparquet')\n",
    "X_test_scaled.to_parquet('C:\\\\ESILV A4\\\\ESILV A4 DIA\\\\Machine Learning\\\\Projet ML\\\\X_test_tree_ready.parquet', engine='fastparquet')\n",
    "\n",
    "# Save targets (y) in CSV \n",
    "y_train_final.to_csv('C:\\\\ESILV A4\\\\ESILV A4 DIA\\\\Machine Learning\\\\Projet ML\\\\y_train_tree_ready.csv', index=False)\n",
    "y_test.to_csv('C:\\\\ESILV A4\\\\ESILV A4 DIA\\\\Machine Learning\\\\Projet ML\\\\y_test_tree_ready.csv', index=False)\n",
    "\n",
    "print(\"\\n Data ready for training\")\n",
    "print(\"Files created \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
