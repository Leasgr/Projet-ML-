{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c82c5f-57b1-41c0-9124-6061e0326463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f472a0-806d-40d8-b50f-01d0688547da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Train: (1258858, 105)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# 1. Load Data\n",
    "# We use the prepared datasets\n",
    "X_train = pd.read_parquet('X_train_tree_ready.parquet', engine='fastparquet')\n",
    "X_test = pd.read_parquet('X_test_tree_ready.parquet', engine='fastparquet')\n",
    "\n",
    "y_train = pd.read_csv('y_train_tree_ready.csv').values.ravel()\n",
    "y_test = pd.read_csv('y_test_tree_ready.csv').values.ravel()\n",
    "\n",
    "print(f\"Data Loaded. Train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4e3250-f1d8-4cd9-8f8d-858540864683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Train shape: (1007086, 105)\n",
      "Optimization Val shape  : (251772, 105)\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a Validation Set for Tuning\n",
    "# We split the Training set to evaluate hyperparameter performance\n",
    "# without touching the final Test set (avoiding data leakage).\n",
    "\n",
    "X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Optimization Train shape: {X_train_opt.shape}\")\n",
    "print(f\"Optimization Val shape  : {X_val_opt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5949c4-a69a-47da-b4ee-187bbeed5920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function defined.\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the Objective Function\n",
    "def objective(trial):\n",
    "    # Define search space for Hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        \n",
    "        # CRITICAL for Imbalanced Data:\n",
    "        # Values > 1 force the model to focus more on Defaults\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0),\n",
    "        \n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist' \n",
    "    }\n",
    "    \n",
    "    # Train model with suggested params\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_opt, y_train_opt)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_prob = model.predict_proba(X_val_opt)[:, 1]\n",
    "    \n",
    "    # We optimize ROC-AUC \n",
    "    return roc_auc_score(y_val_opt, y_prob)\n",
    "\n",
    "print(\"Objective function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67da8e3e-80d5-414f-9ac8-98933de69101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 21:44:57,786] A new study created in memory with name: no-name-7863f5da-f969-48e6-a254-6ac8e7f7f36b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna Study... (This may take time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 21:46:10,624] Trial 0 finished with value: 0.8665980966947268 and parameters: {'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.06956629985753023, 'subsample': 0.7389874975774333, 'colsample_bytree': 0.6724380771616946, 'reg_alpha': 7.974145676139028, 'reg_lambda': 1.2639070982713396, 'min_child_weight': 7, 'scale_pos_weight': 6.6522637499373385}. Best is trial 0 with value: 0.8665980966947268.\n",
      "[I 2025-12-05 21:47:28,496] Trial 1 finished with value: 0.8366453462396922 and parameters: {'n_estimators': 219, 'max_depth': 4, 'learning_rate': 0.011963832962751438, 'subsample': 0.6596125122187885, 'colsample_bytree': 0.7054373772954733, 'reg_alpha': 4.554494529594574, 'reg_lambda': 6.5360669756638625, 'min_child_weight': 9, 'scale_pos_weight': 3.983579389864797}. Best is trial 0 with value: 0.8665980966947268.\n",
      "[I 2025-12-05 21:49:50,543] Trial 2 finished with value: 0.8644825363198132 and parameters: {'n_estimators': 365, 'max_depth': 8, 'learning_rate': 0.21472517371238264, 'subsample': 0.8722358900947678, 'colsample_bytree': 0.6097567638010115, 'reg_alpha': 1.2183196307161526, 'reg_lambda': 4.113183470739235, 'min_child_weight': 5, 'scale_pos_weight': 5.583694917683189}. Best is trial 0 with value: 0.8665980966947268.\n",
      "[I 2025-12-05 21:52:33,146] Trial 3 finished with value: 0.8682655233276908 and parameters: {'n_estimators': 496, 'max_depth': 5, 'learning_rate': 0.041091418313546256, 'subsample': 0.9024506204126408, 'colsample_bytree': 0.8744319685160857, 'reg_alpha': 5.3339590817819715, 'reg_lambda': 3.986237312182903, 'min_child_weight': 10, 'scale_pos_weight': 2.3114941997802365}. Best is trial 3 with value: 0.8682655233276908.\n",
      "[I 2025-12-05 21:53:42,720] Trial 4 finished with value: 0.8672611523302916 and parameters: {'n_estimators': 139, 'max_depth': 8, 'learning_rate': 0.05371479264064699, 'subsample': 0.8409390465589921, 'colsample_bytree': 0.9016790258668244, 'reg_alpha': 7.650194354642197, 'reg_lambda': 7.778809781086088, 'min_child_weight': 6, 'scale_pos_weight': 5.314432965449954}. Best is trial 3 with value: 0.8682655233276908.\n",
      "[I 2025-12-05 21:55:03,523] Trial 5 finished with value: 0.869031405855238 and parameters: {'n_estimators': 280, 'max_depth': 4, 'learning_rate': 0.23395251207770293, 'subsample': 0.6412058452123892, 'colsample_bytree': 0.9686573870996017, 'reg_alpha': 7.933457413371794, 'reg_lambda': 7.135923886949524, 'min_child_weight': 1, 'scale_pos_weight': 8.116590554692307}. Best is trial 5 with value: 0.869031405855238.\n",
      "[I 2025-12-05 21:56:22,289] Trial 6 finished with value: 0.8684388207569155 and parameters: {'n_estimators': 177, 'max_depth': 8, 'learning_rate': 0.17111684263406302, 'subsample': 0.6565955618583436, 'colsample_bytree': 0.9949137113326737, 'reg_alpha': 7.36213662966906, 'reg_lambda': 5.822514935979239, 'min_child_weight': 6, 'scale_pos_weight': 3.7933301360050167}. Best is trial 5 with value: 0.869031405855238.\n",
      "[I 2025-12-05 21:58:28,312] Trial 7 finished with value: 0.8698740691570825 and parameters: {'n_estimators': 455, 'max_depth': 4, 'learning_rate': 0.23325496599102807, 'subsample': 0.7954331349505467, 'colsample_bytree': 0.8882645962849451, 'reg_alpha': 7.595596505091793, 'reg_lambda': 1.2029744990773084, 'min_child_weight': 1, 'scale_pos_weight': 5.198415980729744}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 21:59:04,685] Trial 8 finished with value: 0.8325730179778613 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.030747194476524985, 'subsample': 0.8895777911992466, 'colsample_bytree': 0.6950344027478463, 'reg_alpha': 9.145988796000275, 'reg_lambda': 3.6237301499652252, 'min_child_weight': 2, 'scale_pos_weight': 3.909497899408468}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:01:40,053] Trial 9 finished with value: 0.867327951189703 and parameters: {'n_estimators': 488, 'max_depth': 6, 'learning_rate': 0.24170441880808644, 'subsample': 0.9033200403713249, 'colsample_bytree': 0.8032584462523435, 'reg_alpha': 4.2610778491864, 'reg_lambda': 2.736324801590364, 'min_child_weight': 7, 'scale_pos_weight': 5.249463583752648}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:06:25,477] Trial 10 finished with value: 0.8559249570264686 and parameters: {'n_estimators': 398, 'max_depth': 10, 'learning_rate': 0.28500598699793595, 'subsample': 0.9918670593872828, 'colsample_bytree': 0.8141115253369421, 'reg_alpha': 1.8246073990329155, 'reg_lambda': 0.7338107955210753, 'min_child_weight': 3, 'scale_pos_weight': 1.090864764626744}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:08:29,094] Trial 11 finished with value: 0.8666387213348566 and parameters: {'n_estimators': 303, 'max_depth': 3, 'learning_rate': 0.13916205769892936, 'subsample': 0.6004585404747659, 'colsample_bytree': 0.9840404317238803, 'reg_alpha': 9.86557055266617, 'reg_lambda': 9.991625561275612, 'min_child_weight': 1, 'scale_pos_weight': 9.934808834621597}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:10:40,043] Trial 12 finished with value: 0.8689307735150357 and parameters: {'n_estimators': 287, 'max_depth': 4, 'learning_rate': 0.29967353643953104, 'subsample': 0.7609529556515654, 'colsample_bytree': 0.9269775139073373, 'reg_alpha': 6.135880084155025, 'reg_lambda': 8.342166199375129, 'min_child_weight': 3, 'scale_pos_weight': 8.500833847168456}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:14:11,892] Trial 13 finished with value: 0.8671130021068878 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.22696420627573016, 'subsample': 0.7296363820952311, 'colsample_bytree': 0.8575267563102058, 'reg_alpha': 6.450866652607183, 'reg_lambda': 2.0851737623618973, 'min_child_weight': 1, 'scale_pos_weight': 7.903658284192034}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:16:22,267] Trial 14 finished with value: 0.8688642817941974 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.16690200532137134, 'subsample': 0.8087264195268253, 'colsample_bytree': 0.9364882700768297, 'reg_alpha': 3.421345187635638, 'reg_lambda': 0.0164313804600682, 'min_child_weight': 4, 'scale_pos_weight': 7.695470105946395}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:19:06,414] Trial 15 finished with value: 0.868423903398828 and parameters: {'n_estimators': 337, 'max_depth': 5, 'learning_rate': 0.2655398614987749, 'subsample': 0.6897686205978076, 'colsample_bytree': 0.9513450753173875, 'reg_alpha': 8.659948784738077, 'reg_lambda': 5.394885380133927, 'min_child_weight': 1, 'scale_pos_weight': 9.320718701576018}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:23:02,726] Trial 16 finished with value: 0.8675481768230453 and parameters: {'n_estimators': 427, 'max_depth': 7, 'learning_rate': 0.1994159146478357, 'subsample': 0.9540571220343421, 'colsample_bytree': 0.8519775985758202, 'reg_alpha': 6.552741542595856, 'reg_lambda': 7.057930810858189, 'min_child_weight': 3, 'scale_pos_weight': 6.667478320141323}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:24:47,051] Trial 17 finished with value: 0.8655375763080015 and parameters: {'n_estimators': 241, 'max_depth': 3, 'learning_rate': 0.123897670461175, 'subsample': 0.6151524272622579, 'colsample_bytree': 0.7593092842777172, 'reg_alpha': 9.757137551072944, 'reg_lambda': 8.85573243133467, 'min_child_weight': 2, 'scale_pos_weight': 6.578644477008549}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:30:15,457] Trial 18 finished with value: 0.8662650878464393 and parameters: {'n_estimators': 439, 'max_depth': 10, 'learning_rate': 0.0979505667566957, 'subsample': 0.7833269058296832, 'colsample_bytree': 0.9035995896185788, 'reg_alpha': 3.0190824430206034, 'reg_lambda': 4.681098409854257, 'min_child_weight': 4, 'scale_pos_weight': 8.649686821065048}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:32:49,565] Trial 19 finished with value: 0.8695745744762146 and parameters: {'n_estimators': 345, 'max_depth': 4, 'learning_rate': 0.25454715610694467, 'subsample': 0.6836669417826439, 'colsample_bytree': 0.9661480029660928, 'reg_alpha': 8.264871025874468, 'reg_lambda': 2.6971141904388523, 'min_child_weight': 2, 'scale_pos_weight': 3.1320603292424414}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:37:10,343] Trial 20 finished with value: 0.863596634558657 and parameters: {'n_estimators': 453, 'max_depth': 7, 'learning_rate': 0.259044760337197, 'subsample': 0.7178734450170278, 'colsample_bytree': 0.7577642956844681, 'reg_alpha': 5.616051520318858, 'reg_lambda': 2.611784784686182, 'min_child_weight': 2, 'scale_pos_weight': 2.5701178493581818}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:39:42,505] Trial 21 finished with value: 0.8696197930972706 and parameters: {'n_estimators': 340, 'max_depth': 4, 'learning_rate': 0.19209033661274252, 'subsample': 0.6435951020842476, 'colsample_bytree': 0.9712600314018307, 'reg_alpha': 8.471464353340481, 'reg_lambda': 1.7519958508752693, 'min_child_weight': 1, 'scale_pos_weight': 2.9072969462998426}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:42:34,759] Trial 22 finished with value: 0.8698300435952797 and parameters: {'n_estimators': 344, 'max_depth': 5, 'learning_rate': 0.18892164752849594, 'subsample': 0.6935842301839555, 'colsample_bytree': 0.9109132426009777, 'reg_alpha': 8.763978024063318, 'reg_lambda': 1.6178875756039501, 'min_child_weight': 2, 'scale_pos_weight': 2.2096573003793596}. Best is trial 7 with value: 0.8698740691570825.\n",
      "[I 2025-12-05 22:45:45,261] Trial 23 finished with value: 0.870365391665289 and parameters: {'n_estimators': 389, 'max_depth': 5, 'learning_rate': 0.18192074945625658, 'subsample': 0.807947769041957, 'colsample_bytree': 0.8816885962289402, 'reg_alpha': 6.925821891296819, 'reg_lambda': 1.5149022929866671, 'min_child_weight': 4, 'scale_pos_weight': 1.0766127188250456}. Best is trial 23 with value: 0.870365391665289.\n",
      "[I 2025-12-05 22:49:14,901] Trial 24 finished with value: 0.8702173733059555 and parameters: {'n_estimators': 388, 'max_depth': 5, 'learning_rate': 0.18097346091809108, 'subsample': 0.8233643514514982, 'colsample_bytree': 0.8322222619687861, 'reg_alpha': 7.233576661783961, 'reg_lambda': 0.09017426381525162, 'min_child_weight': 4, 'scale_pos_weight': 1.4105910172990028}. Best is trial 23 with value: 0.870365391665289.\n",
      "[I 2025-12-05 22:53:01,728] Trial 25 finished with value: 0.8704983033005018 and parameters: {'n_estimators': 392, 'max_depth': 6, 'learning_rate': 0.1515731281628733, 'subsample': 0.8115269707565793, 'colsample_bytree': 0.8275943662287653, 'reg_alpha': 6.308404004572228, 'reg_lambda': 0.4856881975808974, 'min_child_weight': 5, 'scale_pos_weight': 1.4621576746649425}. Best is trial 25 with value: 0.8704983033005018.\n",
      "[I 2025-12-05 22:56:34,739] Trial 26 finished with value: 0.8706560034641659 and parameters: {'n_estimators': 391, 'max_depth': 6, 'learning_rate': 0.10996488202094376, 'subsample': 0.8351760928478601, 'colsample_bytree': 0.8287092332968091, 'reg_alpha': 6.952279360304214, 'reg_lambda': 0.12286955247018333, 'min_child_weight': 5, 'scale_pos_weight': 1.2679662128447902}. Best is trial 26 with value: 0.8706560034641659.\n",
      "[I 2025-12-05 22:59:57,857] Trial 27 finished with value: 0.8707817457403982 and parameters: {'n_estimators': 377, 'max_depth': 6, 'learning_rate': 0.09935795175246304, 'subsample': 0.8511576140509081, 'colsample_bytree': 0.7725792378198307, 'reg_alpha': 6.017921681324555, 'reg_lambda': 0.6346800946591648, 'min_child_weight': 5, 'scale_pos_weight': 1.5066724060467958}. Best is trial 27 with value: 0.8707817457403982.\n",
      "[I 2025-12-05 23:03:33,420] Trial 28 finished with value: 0.8705527896052675 and parameters: {'n_estimators': 411, 'max_depth': 6, 'learning_rate': 0.1027341999637203, 'subsample': 0.8349178427319583, 'colsample_bytree': 0.7768931172194209, 'reg_alpha': 0.0891680369276262, 'reg_lambda': 0.5933026263662385, 'min_child_weight': 5, 'scale_pos_weight': 1.831586451016961}. Best is trial 27 with value: 0.8707817457403982.\n",
      "[I 2025-12-05 23:07:39,711] Trial 29 finished with value: 0.8708396203306028 and parameters: {'n_estimators': 416, 'max_depth': 7, 'learning_rate': 0.0837556167812679, 'subsample': 0.8651031003026716, 'colsample_bytree': 0.7692061995983361, 'reg_alpha': 0.2503693497199821, 'reg_lambda': 0.8805999826209923, 'min_child_weight': 7, 'scale_pos_weight': 1.8696573221824924}. Best is trial 29 with value: 0.8708396203306028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimization Complete.\n",
      "Best ROC-AUC: 0.8708\n",
      "Best Params:\n",
      "  n_estimators: 416\n",
      "  max_depth: 7\n",
      "  learning_rate: 0.0837556167812679\n",
      "  subsample: 0.8651031003026716\n",
      "  colsample_bytree: 0.7692061995983361\n",
      "  reg_alpha: 0.2503693497199821\n",
      "  reg_lambda: 0.8805999826209923\n",
      "  min_child_weight: 7\n",
      "  scale_pos_weight: 1.8696573221824924\n"
     ]
    }
   ],
   "source": [
    "# 4. Run Optimization\n",
    "print(\"Starting Optuna Study... (This may take time)\")\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30) # 30 trials is a good start\n",
    "\n",
    "print(\"\\n Optimization Complete.\")\n",
    "print(f\"Best ROC-AUC: {study.best_value:.4f}\")\n",
    "print(\"Best Params:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bbaff56-1099-45f8-bd44-ed1e8c8bf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 416,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.0837556167812679,\n",
    "    'subsample': 0.8651031003026716,\n",
    "    'colsample_bytree': 0.7692061995983361,\n",
    "    'reg_alpha': 0.2503693497199821,\n",
    "    'reg_lambda': 0.8805999826209923,\n",
    "    'min_child_weight': 7,\n",
    "    'scale_pos_weight': 1.8696573221824924, \n",
    "    \n",
    "    \n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbe3f30-aa91-4b4c-b12c-4cba4d39c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining LightGBM with BEST parameters on full Train Set...\n",
      "Final Model Trained.\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "best_params['n_jobs'] = -1\n",
    "best_params['random_state'] = 42\n",
    "\n",
    "print(\"Retraining LightGBM with BEST parameters on full Train Set...\")\n",
    "\n",
    "final_model = LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = final_model.predict(X_test)\n",
    "y_prob_tuned = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Final Model Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2474e8-513e-472b-8155-f19ba14e9cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMIZATION RESULTS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM (Default)</th>\n",
       "      <th>LightGBM (Tuned)</th>\n",
       "      <th>GAIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall (Defaults)</th>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.3683</td>\n",
       "      <td>-0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>-0.0306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   LightGBM (Default)  LightGBM (Tuned)    GAIN\n",
       "Metric                                                         \n",
       "ROC-AUC                        0.7055            0.7196  0.0141\n",
       "Recall (Defaults)              0.4572            0.5841  0.1269\n",
       "Precision                      0.3840            0.3683 -0.0157\n",
       "F1-Score                       0.4174            0.4518  0.0344\n",
       "Accuracy                       0.7236            0.6930 -0.0306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "\n",
    "# 5. Final Comparison Table: Before vs After Tuning\n",
    "\n",
    "# Scores for Default LightGBM \n",
    "auc_default = 0.7055\n",
    "rec_default = 0.4572\n",
    "prec_default = 0.3840\n",
    "f1_default = 0.4174\n",
    "acc_default = 0.7236  \n",
    "\n",
    "# Calculate Scores for Tuned Model\n",
    "auc_tuned = roc_auc_score(y_test, y_prob_tuned)\n",
    "rec_tuned = classification_report(y_test, y_pred_tuned, output_dict=True)['1']['recall']\n",
    "prec_tuned = classification_report(y_test, y_pred_tuned, output_dict=True)['1']['precision']\n",
    "f1_tuned = classification_report(y_test, y_pred_tuned, output_dict=True)['1']['f1-score']\n",
    "acc_tuned = accuracy_score(y_test, y_pred_tuned) \n",
    "\n",
    "# Create Data Dictionary \n",
    "data = {\n",
    "    \"Metric\": [\"ROC-AUC\", \"Recall (Defaults)\", \"Precision\", \"F1-Score\", \"Accuracy\"],\n",
    "    \"LightGBM (Default)\": [auc_default, rec_default, prec_default, f1_default, acc_default],\n",
    "    \"LightGBM (Tuned)\": [auc_tuned, rec_tuned, prec_tuned, f1_tuned, acc_tuned]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_compare = pd.DataFrame(data).set_index(\"Metric\")\n",
    "\n",
    "# Calculate Gain\n",
    "df_compare[\"GAIN\"] = df_compare[\"LightGBM (Tuned)\"] - df_compare[\"LightGBM (Default)\"]\n",
    "\n",
    "print(\"\\n=== OPTIMIZATION RESULTS ===\")\n",
    "display(df_compare.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa86c9a-e2e6-40ee-8cde-e173faaf6408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
